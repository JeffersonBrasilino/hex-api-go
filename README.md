# ğŸ“¦ gomes - Sistema de Mensagens para Arquitetura Hexagonal

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Bootstrap](#-bootstrap)
- [Componentes Principais](#-componentes-principais)
- [CQRS](#-cqrs)
- [Processamento AssÃ­ncrono](#-async-processing)
  - [PadrÃµes de PublicaÃ§Ã£o](#-padrÃµes-de-publicaÃ§Ã£o)
  - [PadrÃµes de Consumo](#-padrÃµes-de-consumo)
  - [ResiliÃªncia](#-resiliÃªncia)
  - [Kafka](#-kafka)

## ğŸ¯ VisÃ£o Geral

O **gomes** Ã© um plugin robusto e flexÃ­vel para sistemas de mensagens em arquitetura hexagonal, implementando padrÃµes de Enterprise Integration Patterns (EIP) e Command Query Responsibility Segregation (CQRS). Este sistema oferece uma abstraÃ§Ã£o completa para comunicaÃ§Ã£o assÃ­ncrona entre componentes, facilitando a construÃ§Ã£o de aplicaÃ§Ãµes distribuÃ­das e escalÃ¡veis.

### CaracterÃ­sticas Principais

- **Arquitetura Hexagonal**: SeparaÃ§Ã£o clara entre domÃ­nio, aplicaÃ§Ã£o e infraestrutura
- **PadrÃ£o CQRS**: SeparaÃ§Ã£o entre comandos (modificaÃ§Ã£o) e queries (consulta)
- **Event-Driven Architecture**: Processamento assÃ­ncrono baseado em eventos
- **Enterprise Integration Patterns**: ImplementaÃ§Ã£o de padrÃµes consolidados da indÃºstria
- **ResiliÃªncia**: Suporte a retry automÃ¡tico e dead letter channels
- **MÃºltiplos Drivers**: Suporte a diferentes sistemas de mensagens (Kafka, RabbitMQ, etc.)
- **Processamento Paralelo**: Suporte a mÃºltiplos processadores concorrentes

### PadrÃµes e Abordagens Utilizadas

- **Message Channel**: ComunicaÃ§Ã£o entre componentes atravÃ©s de canais
- **Message Router**: Roteamento inteligente de mensagens baseado em conteÃºdo
- **Dead Letter Channel**: Gerenciamento de mensagens que falharam no processamento
- **Message Dispatcher**: DistribuiÃ§Ã£o de mensagens para handlers apropriados
- **Event-Driven Consumer**: Consumo assÃ­ncrono com processamento paralelo
- **Polling Consumer**: Consumo periÃ³dico para processamento em lote

### Estrutura de Pastas do Plugin

```
pkg/core/infrastructure/gomes/
â”œâ”€â”€ bus/                    # ImplementaÃ§Ãµes CQRS
â”‚   â”œâ”€â”€ command_bus.go      # Processamento de comandos
â”‚   â”œâ”€â”€ query_bus.go        # Processamento de queries
â”‚   â””â”€â”€ event_bus.go        # Processamento de eventos
â”œâ”€â”€ channel/                # ImplementaÃ§Ãµes de canais
â”‚   â”œâ”€â”€ kafka/              # Driver Kafka
â”‚   â”‚   â”œâ”€â”€ connection.go   # Gerenciamento de conexÃµes
â”‚   â”‚   â”œâ”€â”€ inbound_channel_adapter.go  # Consumo de mensagens
â”‚   â”‚   â”œâ”€â”€ outbound_channel_adapter.go # PublicaÃ§Ã£o de mensagens
â”‚   â”‚   â””â”€â”€ message_translator.go       # TraduÃ§Ã£o de mensagens
â”‚   â”œâ”€â”€ pubsub_channel.go   # Canal publish-subscribe
â”‚   â””â”€â”€ point_to_point.go   # Canal point-to-point
â”œâ”€â”€ container/              # Gerenciamento de dependÃªncias
â”‚   â””â”€â”€ generic_container.go
â”œâ”€â”€ message/                # Core do sistema
â”‚   â”œâ”€â”€ message.go          # Estrutura base de mensagens
â”‚   â”œâ”€â”€ message_builder.go  # Builder para construÃ§Ã£o de mensagens
â”‚   â”œâ”€â”€ channel/            # Canais de mensagens
â”‚   â”œâ”€â”€ endpoint/           # Endpoints de processamento
â”‚   â”‚   â”œâ”€â”€ event_driven_consumer.go  # Consumer event-driven
â”‚   â”‚   â”œâ”€â”€ polling_consumer.go       # Consumer polling
â”‚   â”‚   â”œâ”€â”€ gateway.go                # Gateway de processamento
â”‚   â”‚   â””â”€â”€ interfaces.go             # Interfaces dos endpoints
â”‚   â”œâ”€â”€ handler/            # Handlers de mensagens
â”‚   â”‚   â”œâ”€â”€ dead_letter.go  # Handler para dead letter
â”‚   â”‚   â””â”€â”€ retry_handler.go # Handler para retry
â”‚   â””â”€â”€ router/             # Roteamento de mensagens
â””â”€â”€ message_system.go       # Entry point principal
```

## ğŸš€ Bootstrap

O Bootstrap Ã© o processo de inicializaÃ§Ã£o do gomes, onde todos os componentes sÃ£o registrados e configurados antes do sistema comeÃ§ar a processar mensagens. Este processo Ã© fundamental para garantir que o sistema funcione corretamente.

### Exemplo

```go
package main

import (
    "context"
    "log/slog"
    "os/signal"
    "syscall"
    "time"

    "github.com/jeffersonbrasilino/gomes"
    kafka "github.com/jeffersonbrasilino/gomes/channel/kafka"
)

func main() {
    // Configurar contexto para graceful shutdown
    ctx, stop := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)
    defer stop()

    slog.Info("Iniciando gomes...")

    // 1. REGISTRAR HANDLERS
    // Registre todos os handlers de comandos, queries e eventos
    gomes.AddActionHandler(&CreateUserHandler{})
    gomes.AddActionHandler(&GetUserHandler{})
    gomes.AddActionHandler(&UserCreatedEventHandler{})

    // 2. CONFIGURAR CONEXÃ•ES
    // Configure conexÃµes com sistemas de mensagens (Kafka, RabbitMQ, etc.)
    gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    )

    // 3. CONFIGURAR CANAIS DE PUBLICAÃ‡ÃƒO
    // Configure canais para envio de mensagens
    publisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
    )
    gomes.AddPublisherChannel(publisherChannel)

    // Configure canal de Dead Letter Queue
    dlqPublisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.dlq",
    )
    gomes.AddPublisherChannel(dlqPublisherChannel)

    // 4. CONFIGURAR CANAIS DE CONSUMO
    // Configure canais para recebimento de mensagens
    consumerChannel := kafka.NewConsumerChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
        "test_consumer",
    )
    // Configure resiliÃªncia
    consumerChannel.WithRetryTimes(2_000, 3_000)
    consumerChannel.WithDeadLetterChannelName("gomes.dlq")

    gomes.AddConsumerChannel(consumerChannel)

    // 5. INICIAR O SISTEMA
    // Inicie o gomes - este passo Ã© obrigatÃ³rio
    gomes.Start()
    slog.Info("gomes iniciado com sucesso!")

    // 6. CONFIGURAR CONSUMERS
    // Configure e inicie os consumers
    consumer, err := gomes.EventDrivenConsumer("test_consumer")
    if err != nil {
        slog.Error("Erro ao criar consumer", "error", err)
        return
    }

    // Execute consumer com configuraÃ§Ãµes especÃ­ficas
    go consumer.WithAmountOfProcessors(2).
        WithMessageProcessingTimeout(30000).
        WithStopOnError(false).
        Run(ctx)

    // 7. SISTEMA OPERACIONAL
    // Aqui o sistema estÃ¡ pronto para processar mensagens
    slog.Info("Sistema operacional - processando mensagens...")

    // Exemplo de uso dos buses
    go publishMessages(ctx)

    // 8. GRACEFUL SHUTDOWN
    // Aguarde sinal de interrupÃ§Ã£o
    <-ctx.Done()
    slog.Info("Iniciando shutdown gracioso...")

    // Encerre o sistema graciosamente
    gomes.Shutdown()
    slog.Info("gomes encerrado com sucesso!")
}

func publishMessages(ctx context.Context) {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            // Publique comandos
            commandBus := gomes.CommandBusByChannel("gomes.topic")
            commandBus.SendAsync(ctx, &CreateUserCommand{
                Username: "user_" + time.Now().Format("20060102150405"),
                Password: "secure_password",
            })

            // Publique queries
            queryBus := gomes.QueryBusByChannel("gomes.topic")
            queryBus.SendAsync(ctx, &GetUserQuery{
                UserID: "123",
            })

            // Publique eventos
            eventBus := gomes.EventBusByChannel("gomes.topic")
            eventBus.Publish(ctx, &UserCreatedEvent{
                UserID:    "123",
                Username:  "john_doe",
                Timestamp: time.Now(),
            })
        }
    }
}
```

### MÃ©todos de Bootstrap

#### Registro de Componentes

- **`AddActionHandler(handler)`**: Registra handlers de comandos, queries e eventos
- **`AddChannelConnection(connection)`**: Registra conexÃµes com sistemas de mensagens
- **`AddPublisherChannel(channel)`**: Registra canais de publicaÃ§Ã£o
- **`AddConsumerChannel(channel)`**: Registra canais de consumo

#### Controle do Sistema

- **`Start()`**: Inicia o gomes (obrigatÃ³rio)
- **`Shutdown()`**: Encerra o sistema graciosamente
- **`ShowActiveEndpoints()`**: Mostra endpoints ativos para debug

### Boas PrÃ¡ticas de Bootstrap

1. **Ordem Importante**: Sempre registre handlers antes de iniciar o sistema
2. **ConexÃµes Ãšnicas**: Use o mesmo nome de conexÃ£o para reutilizar instÃ¢ncias
3. **Graceful Shutdown**: Sempre configure graceful shutdown para produÃ§Ã£o
4. **Error Handling**: Trate erros durante a inicializaÃ§Ã£o
5. **Logging**: Use logging adequado para monitorar o processo

## ğŸ”§ Componentes Principais

### Diagrama de Fluxo

```mermaid
flowchart TD
    A[Cliente] -->|1. Envia Mensagem| B[gomes]
    B -->|2. Identifica Tipo| C{Tipo de Mensagem}
    C -->|Command| D[CommandBus]
    C -->|Query| E[QueryBus]
    C -->|Event| F[EventBus]

    D -->|3. Roteia| G[MessageRouter]
    E -->|3. Roteia| G
    F -->|3. Roteia| G

    G -->|4. Despacha| H[MessageHandler]
    H -->|5. Processa| I[Domain Logic]
    I -->|6. Resultado| H
    H -->|7. Resposta| G
    G -->|8. Retorno| B
    B -->|9. Entrega| A

    J[Channel Adapter] -->|Consumo| K[Consumer Endpoint]
    K -->|Processamento| L[Gateway]
    L -->|Retry/Dead Letter| M[Resilience Layer]
```

### Diagrama de ExecuÃ§Ã£o

```mermaid
sequenceDiagram
    participant C as Cliente
    participant MS as gomes
    participant CB as CommandBus
    participant R as Router
    participant H as Handler
    participant D as Domain
    participant CA as ChannelAdapter
    participant CE as ConsumerEndpoint

    Note over C,CE: Fluxo de PublicaÃ§Ã£o
    C->>MS: Send(Command)
    MS->>CB: Route(Command)
    CB->>R: Dispatch(Command)
    R->>H: Handle(Command)
    H->>D: Execute Business Logic
    D-->>H: Result
    H-->>R: Return Result
    R-->>CB: Forward Result
    CB-->>MS: Response
    MS-->>C: Return Result

    Note over C,CE: Fluxo de Consumo
    CA->>CE: Receive Message
    CE->>R: Process Message
    R->>H: Handle Message
    H->>D: Execute Logic
    D-->>H: Result
    H-->>R: Return Result
    R-->>CE: Acknowledge
    CE-->>CA: Message Processed
```

## âš¡ CQRS

O gomes implementa o padrÃ£o **Command Query Responsibility Segregation (CQRS)** de forma nativa, separando claramente as operaÃ§Ãµes de modificaÃ§Ã£o (Commands) das operaÃ§Ãµes de consulta (Queries), alÃ©m de incluir o processamento de eventos (Events) para notificaÃ§Ãµes assÃ­ncronas.

### Arquitetura CQRS no gomes

```mermaid
flowchart TD
    A[Cliente] --> B{Tipo de OperaÃ§Ã£o}

    B -->|ModificaÃ§Ã£o| C[Command Bus]
    B -->|Consulta| D[Query Bus]
    B -->|NotificaÃ§Ã£o| E[Event Bus]

    C --> F[Command Handler]
    D --> G[Query Handler]
    E --> H[Event Handler 1]
    E --> I[Event Handler 2]
    E --> J[Event Handler N]

    F --> K[Domain Logic<br/>ModificaÃ§Ã£o de Estado]
    G --> L[Domain Logic<br/>Leitura de Dados]
    H --> M[Side Effects<br/>Email, Log, etc.]
    I --> M
    J --> M

    K --> N[Resposta SÃ­ncrona]
    L --> N
    M --> O[Processamento AssÃ­ncrono]
```

### Diagrama de ExecuÃ§Ã£o CQRS

```mermaid
sequenceDiagram
    participant C as Cliente
    participant CB as CommandBus
    participant QB as QueryBus
    participant EB as EventBus
    participant CH as CommandHandler
    participant QH as QueryHandler
    participant EH1 as EventHandler1
    participant EH2 as EventHandler2
    participant D as Domain

    Note over C,D: Command Flow
    C->>CB: Send(Command)
    CB->>CH: Handle(Command)
    CH->>D: Execute Business Logic
    D-->>CH: Result
    CH-->>CB: Response
    CB-->>C: Return Result

    Note over C,D: Query Flow
    C->>QB: Send(Query)
    QB->>QH: Handle(Query)
    QH->>D: Read Data
    D-->>QH: Data
    QH-->>QB: Response
    QB-->>C: Return Data

    Note over C,D: Event Flow
    C->>EB: Publish(Event)
    EB->>EH1: Handle(Event)
    EB->>EH2: Handle(Event)
    EH1->>D: Side Effect 1
    EH2->>D: Side Effect 2
    EH1-->>EB: Acknowledged
    EH2-->>EB: Acknowledged
    EB-->>C: Published
```

### ImplementaÃ§Ã£o dos Buses

#### Command Bus

O Command Bus Ã© responsÃ¡vel por processar comandos que modificam o estado do sistema. Cada comando tem exatamente um handler e retorna uma resposta sÃ­ncrona.

```go
// DefiniÃ§Ã£o de um Command
type CreateUserCommand struct {
    Username string `json:"username"`
    Email    string `json:"email"`
    Password string `json:"password"`
}

func (c *CreateUserCommand) Name() string {
    return "CreateUser"
}

// Handler do Command
type CreateUserHandler struct {
    userRepository UserRepository
}

func (h *CreateUserHandler) Handle(ctx context.Context, cmd *CreateUserCommand) (*UserCreatedResult, error) {
    // ValidaÃ§Ã£o
    if cmd.Username == "" || cmd.Email == "" {
        return nil, errors.New("username and email are required")
    }

    // CriaÃ§Ã£o do usuÃ¡rio
    user := &User{
        ID:       uuid.New().String(),
        Username: cmd.Username,
        Email:    cmd.Email,
        Password: hashPassword(cmd.Password),
    }

    // PersistÃªncia
    err := h.userRepository.Save(ctx, user)
    if err != nil {
        return nil, fmt.Errorf("failed to save user: %w", err)
    }

    // Retorno do resultado
    return &UserCreatedResult{
        UserID:   user.ID,
        Username: user.Username,
        Email:    user.Email,
    }, nil
}

// Uso do Command Bus
func createUser() {
    commandBus := gomes.CommandBus()

    result, err := commandBus.Send(context.Background(), &CreateUserCommand{
        Username: "john_doe",
        Email:    "john@example.com",
        Password: "secure_password",
    })

    if err != nil {
        log.Printf("Erro ao criar usuÃ¡rio: %v", err)
        return
    }

    log.Printf("UsuÃ¡rio criado: %+v", result)
}
```

#### Query Bus

O Query Bus Ã© responsÃ¡vel por processar consultas que leem dados do sistema. Cada query tem exatamente um handler e retorna dados sÃ­ncronos.

```go
// DefiniÃ§Ã£o de uma Query
type GetUserByIDQuery struct {
    UserID string `json:"user_id"`
}

func (q *GetUserByIDQuery) Name() string {
    return "GetUserByID"
}

// Handler da Query
type GetUserByIDHandler struct {
    userRepository UserRepository
}

func (h *GetUserByIDHandler) Handle(ctx context.Context, query *GetUserByIDQuery) (*User, error) {
    // Busca o usuÃ¡rio
    user, err := h.userRepository.FindByID(ctx, query.UserID)
    if err != nil {
        return nil, fmt.Errorf("failed to find user: %w", err)
    }

    if user == nil {
        return nil, errors.New("user not found")
    }

    // Retorna os dados (sem informaÃ§Ãµes sensÃ­veis)
    return &User{
        ID:       user.ID,
        Username: user.Username,
        Email:    user.Email,
        // Password nÃ£o Ã© retornado por seguranÃ§a
    }, nil
}

// Uso do Query Bus
func getUser() {
    queryBus := gomes.QueryBus()

    user, err := queryBus.SendAsync(context.Background(), &GetUserByIDQuery{
        UserID: "123",
    })

    if err != nil {
        log.Printf("Erro ao buscar usuÃ¡rio: %v", err)
        return
    }

    log.Printf("UsuÃ¡rio encontrado: %+v", user)
}
```

#### Event Bus

O Event Bus Ã© responsÃ¡vel por processar eventos que notificam sobre mudanÃ§as no sistema. Um evento pode ter mÃºltiplos handlers e Ã© processado de forma assÃ­ncrona.

```go
// DefiniÃ§Ã£o de um Event
type UserCreatedEvent struct {
    UserID    string    `json:"user_id"`
    Username  string    `json:"username"`
    Email     string    `json:"email"`
    Timestamp time.Time `json:"timestamp"`
}

func (e *UserCreatedEvent) Name() string {
    return "UserCreated"
}

// Handler 1: Envio de Email
type UserCreatedEmailHandler struct {
    emailService EmailService
}

func (h *UserCreatedEmailHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Enviar email de boas-vindas
    email := &Email{
        To:      evt.Email,
        Subject: "Bem-vindo!",
        Body:    fmt.Sprintf("OlÃ¡ %s, sua conta foi criada com sucesso!", evt.Username),
    }

    return h.emailService.Send(ctx, email)
}

// Handler 2: Log de Auditoria
type UserCreatedAuditHandler struct {
    auditLogger AuditLogger
}

func (h *UserCreatedAuditHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Registrar no log de auditoria
    return h.auditLogger.Log(ctx, &AuditEntry{
        Action:    "USER_CREATED",
        UserID:    evt.UserID,
        Timestamp: evt.Timestamp,
        Details:   fmt.Sprintf("User %s created with email %s", evt.Username, evt.Email),
    })
}

// Handler 3: NotificaÃ§Ã£o Push
type UserCreatedNotificationHandler struct {
    notificationService NotificationService
}

func (h *UserCreatedNotificationHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Enviar notificaÃ§Ã£o push
    notification := &Notification{
        UserID:  evt.UserID,
        Title:   "Conta Criada",
        Message: "Sua conta foi criada com sucesso!",
        Type:    "SUCCESS",
    }

    return h.notificationService.Send(ctx, notification)
}

// Uso do Event Bus
func publishUserCreated(user *User) {
    eventBus := gomes.EventBus()

    err := eventBus.Publish(context.Background(), &UserCreatedEvent{
        UserID:    user.ID,
        Username:  user.Username,
        Email:     user.Email,
        Timestamp: time.Now(),
    })

    if err != nil {
        log.Printf("Erro ao publicar evento: %v", err)
    }
}
```

### BenefÃ­cios da ImplementaÃ§Ã£o CQRS

1. **SeparaÃ§Ã£o de Responsabilidades**: Commands modificam, Queries leem, Events notificam
2. **Escalabilidade Independente**: Cada tipo pode ser escalado separadamente
3. **OtimizaÃ§Ã£o de Performance**: Queries podem usar views otimizadas
4. **Flexibilidade**: Handlers podem ser adicionados/removidos independentemente
5. **Testabilidade**: Cada handler pode ser testado isoladamente
6. **Manutenibilidade**: CÃ³digo mais organizado e fÃ¡cil de manter

### MÃ©todos dos Buses

#### Command Bus

- **`SendAsync(ctx, command)`**: Envia comando de forma assÃ­ncrona
- **`SendRawAsync(ctx, route, payload, headers)`**: Envia comando com payload e headers customizados

#### Query Bus

- **`SendAsync(ctx, query)`**: Envia query de forma assÃ­ncrona
- **`SendRawAsync(ctx, route, payload, headers)`**: Envia query com payload customizado e headers customizados

#### Event Bus

- **`Publish(ctx, event)`**: Publica evento de forma assÃ­ncrona
- **`PublishRaw(ctx, route, payload, headers)`**: Publica evento com payload customizado e headers customizados

## â± Processamento assÃ­ncrono

### ğŸ“¤ PadrÃµes de PublicaÃ§Ã£o

#### Comandos

Os comandos representam aÃ§Ãµes que modificam o estado do sistema. Eles sÃ£o processados de forma sÃ­ncrona e devem retornar uma resposta.

##### Exemplo de Uso

```go
// 1. Defina seu comando
type CreateUserCommand struct {
    Username string `json:"username"`
    Password string `json:"password"`
}

func (c *CreateUserCommand) Name() string {
    return "createUser"
}

// 2. Implemente o handler
type CreateUserHandler struct{}

func (h *CreateUserHandler) Handle(ctx context.Context, cmd *CreateUserCommand) (*ResultCm, error) {
    // Implemente a lÃ³gica de negÃ³cio
    fmt.Println("process command ok")
    return &ResultCm{"User created successfully"}, nil
}

// 3. Configure e use o sistema
func main() {
    // Configure conexÃ£o Kafka
    gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    )

    // Configure canal de publicaÃ§Ã£o
    publisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
    )
    gomes.AddPublisherChannel(publisherChannel)

    // Registre o handler
    gomes.AddActionHandler(&CreateUserHandler{})

    // Inicie o sistema
    gomes.Start()

    // Use o command bus
    commandBus := gomes.CommandBusByChannel("gomes.topic")
    commandBus.SendAsync(context.Background(), &CreateUserCommand{
        Username: "teste",
        Password: "123",
    })
}
```

##### MÃ©todos do Fluxo de Comando

- **`SendAsync(ctx, command)`**: Envia comando de forma assÃ­ncrona
- **`SendRawAsync(ctx, route, payload, headers)`**: Envia comando com payload customizado
- **`Handle(ctx, command)`**: Processa o comando no handler
- **`Route(command)`**: Roteia o comando para o handler apropriado

#### Queries

As queries representam consultas que nÃ£o modificam o estado do sistema. Elas sÃ£o processadas de forma sÃ­ncrona e retornam dados.

##### Exemplo de Uso

```go
// 1. Defina sua query
type GetUserQuery struct {
    UserID string `json:"user_id"`
}

func (q *GetUserQuery) Name() string {
    return "getUser"
}

// 2. Implemente o handler
type GetUserHandler struct{}

func (h *GetUserHandler) Handle(ctx context.Context, query *GetUserQuery) (*User, error) {
    // Implemente a lÃ³gica de consulta
    return &User{ID: query.UserID, Name: "John Doe"}, nil
}

// 3. Use o query bus
func getUser() {
    queryBus := gomes.QueryBusByChannel("gomes.topic")
    user, err := queryBus.SendAsync(context.Background(), &GetUserQuery{
        UserID: "123",
    })
}
```

##### MÃ©todos do Fluxo de Query

- **`SendAsync(ctx, query)`**: Envia query de forma assÃ­ncrona
- **`SendRawAsync(ctx, route, payload, headers)`**: Envia query com payload customizado
- **`Handle(ctx, query)`**: Processa a query no handler
- **`Route(query)`**: Roteia a query para o handler apropriado

#### Eventos

Os eventos representam notificaÃ§Ãµes sobre mudanÃ§as no sistema. Eles sÃ£o processados de forma assÃ­ncrona e podem ter mÃºltiplos handlers.

##### Exemplo de Uso

```go
// 1. Defina seu evento
type UserCreatedEvent struct {
    UserID    string    `json:"user_id"`
    Username  string    `json:"username"`
    Timestamp time.Time `json:"timestamp"`
}

func (e *UserCreatedEvent) Name() string {
    return "userCreated"
}

// 2. Implemente handlers do evento
type EmailNotificationHandler struct{}

func (h *EmailNotificationHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Enviar email de boas-vindas
    fmt.Printf("Sending welcome email to user %s\n", evt.Username)
    return nil
}

type AuditLogHandler struct{}

func (h *AuditLogHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Registrar no log de auditoria
    fmt.Printf("Audit log: User %s created at %s\n", evt.Username, evt.Timestamp)
    return nil
}

// 3. Use o event bus
func publishUserCreated() {
    eventBus := gomes.EventBusByChannel("gomes.topic")
    eventBus.Publish(context.Background(), &UserCreatedEvent{
        UserID:    "123",
        Username:  "john_doe",
        Timestamp: time.Now(),
    })
}
```

##### MÃ©todos do Fluxo de Evento

- **`Publish(ctx, event)`**: Publica evento de forma assÃ­ncrona
- **`PublishRaw(ctx, route, payload, headers)`**: Publica evento com payload customizado
- **`Handle(ctx, event)`**: Processa o evento em todos os handlers registrados
- **`Route(event)`**: Roteia o evento para todos os handlers apropriados

### ğŸ“¥ PadrÃµes de Consumo

#### Event-Driven Consumer

O Event-Driven Consumer processa mensagens de forma assÃ­ncrona e em tempo real, ideal para sistemas que precisam de baixa latÃªncia e alta throughput.

##### CaracterÃ­sticas

- **Processamento AssÃ­ncrono**: Mensagens sÃ£o processadas assim que chegam
- **MÃºltiplos Processadores**: Suporte a processamento paralelo
- **Baixa LatÃªncia**: Processamento imediato das mensagens
- **Alto Throughput**: Capacidade de processar muitas mensagens simultaneamente

##### Exemplo de Uso

```go
func main() {
    // Configure conexÃ£o e canais
    gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    )

    // Configure consumer channel com resiliÃªncia
    topicConsumerChannel := kafka.NewConsumerChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
        "test_consumer",
    )
    topicConsumerChannel.WithRetryTimes(2_000, 3_000)
    topicConsumerChannel.WithDeadLetterChannelName("gomes.dlq")

    // Registre canais e handlers
    gomes.AddConsumerChannel(topicConsumerChannel)
    gomes.AddActionHandler(&CreateUserHandler{})

    // Inicie o sistema
    gomes.Start()

    // Configure event-driven consumer
    consumer, err := gomes.EventDrivenConsumer("test_consumer")
    if err != nil {
        panic(err)
    }

    // Execute com configuraÃ§Ãµes especÃ­ficas
    go consumer.WithAmountOfProcessors(1).
        WithMessageProcessingTimeout(50000).
        WithStopOnError(false).
        Run(ctx)
}
```

##### MÃ©todos do Event-Driven Consumer

- **`WithAmountOfProcessors(count)`**: Define nÃºmero de processadores paralelos
- **`WithMessageProcessingTimeout(timeout)`**: Define timeout para processamento
- **`WithStopOnError(stop)`**: Define se deve parar em caso de erro
- **`Run(ctx)`**: Inicia o processamento assÃ­ncrono

#### Polling Consumer

O Polling Consumer processa mensagens de forma periÃ³dica, ideal para processamento em lote e sistemas que nÃ£o precisam de tempo real.

##### CaracterÃ­sticas

- **Processamento PeriÃ³dico**: Verifica mensagens em intervalos definidos
- **Processamento em Lote**: Ideal para operaÃ§Ãµes que processam mÃºltiplas mensagens
- **Controle de Recursos**: Menor uso de recursos do sistema
- **Maior LatÃªncia**: Processamento nÃ£o Ã© imediato

##### Exemplo de Uso

```go
func main() {
    // Configure consumer polling
    consumer := gomes.NewPollingConsumer("batch-consumer")

    // Configure parÃ¢metros
    consumer.WithPollIntervalMilliseconds(5000)      // Poll a cada 5 segundos
    consumer.WithProcessingDelayMilliseconds(1000)  // Delay de 1 segundo entre processamentos
    consumer.WithProcessingTimeoutMilliseconds(30000) // Timeout de 30 segundos
    consumer.WithStopOnError(false)                  // NÃ£o parar em caso de erro

    // Inicie o polling
    go consumer.Run(ctx)
}
```

##### MÃ©todos do Polling Consumer

- **`WithPollIntervalMilliseconds(interval)`**: Define intervalo de polling
- **`WithProcessingDelayMilliseconds(delay)`**: Define delay entre processamentos
- **`WithProcessingTimeoutMilliseconds(timeout)`**: Define timeout para processamento
- **`WithStopOnError(stop)`**: Define se deve parar em caso de erro
- **`Run(ctx)`**: Inicia o polling periÃ³dico

#### ComparaÃ§Ã£o: Event-Driven vs Polling

| Aspecto             | Event-Driven          | Polling                      |
| ------------------- | --------------------- | ---------------------------- |
| **LatÃªncia**        | Baixa (tempo real)    | Alta (periÃ³dica)             |
| **Throughput**      | Alto                  | MÃ©dio                        |
| **Uso de Recursos** | Alto                  | Baixo                        |
| **Complexidade**    | MÃ©dia                 | Baixa                        |
| **Escalabilidade**  | Excelente             | Boa                          |
| **Casos de Uso**    | Tempo real, streaming | Batch processing, relatÃ³rios |

##### PrÃ³s e Contras

**Event-Driven Consumer:**

âœ… **PrÃ³s:**

- Processamento em tempo real
- Alta eficiÃªncia para streaming
- Escalabilidade horizontal
- Baixa latÃªncia

âŒ **Contras:**

- Maior complexidade de configuraÃ§Ã£o
- Maior uso de recursos
- Pode causar backpressure se nÃ£o configurado adequadamente

**Polling Consumer:**

âœ… **PrÃ³s:**

- Simplicidade de implementaÃ§Ã£o
- Baixo uso de recursos
- Controle preciso sobre quando processar
- Ideal para batch processing

âŒ **Contras:**

- Maior latÃªncia
- Menor throughput
- Pode perder mensagens se o intervalo for muito longo

### ğŸ›¡ï¸ ResiliÃªncia

#### Retry Pattern

O padrÃ£o de retry permite que o sistema tente processar uma mensagem novamente em caso de falha temporÃ¡ria, aumentando a robustez do sistema.

##### Como Funciona

O sistema implementa um handler de retry que envolve o handler original e tenta reprocessar a mensagem em caso de erro, com intervalos configurÃ¡veis entre as tentativas.

##### Diagrama de Fluxo do Retry

```mermaid
flowchart TD
    A[Mensagem Recebida] --> B[Handler Original]
    B --> C{Processamento OK?}
    C -->|Sim| D[Sucesso]
    C -->|NÃ£o| E[Incrementar Tentativa]
    E --> F{Tentativas < MÃ¡ximo?}
    F -->|Sim| G[Aguardar Intervalo]
    G --> H[Tentar Novamente]
    H --> B
    F -->|NÃ£o| I[Falha Final]
    I --> J[Dead Letter Channel]
```

##### Diagrama de ExecuÃ§Ã£o do Retry

```mermaid
sequenceDiagram
    participant M as Message
    participant RH as RetryHandler
    participant OH as OriginalHandler
    participant DLC as DeadLetterChannel

    M->>RH: Process Message
    RH->>OH: Handle Message
    OH-->>RH: Error

    loop Retry Attempts
        RH->>RH: Wait Interval
        RH->>OH: Retry Handle
        OH-->>RH: Error
    end

    RH->>DLC: Send to Dead Letter
    DLC-->>RH: Acknowledged
```

##### Exemplo de ConfiguraÃ§Ã£o

```go
// Configure retry com intervalos especÃ­ficos
topicConsumerChannel := kafka.NewConsumerChannelAdapterBuilder(
    "defaultConKafka",
    "gomes.topic",
    "test_consumer",
)

// Configure retry: [2000ms, 3000ms] - duas tentativas com intervalos de 2s e 3s
topicConsumerChannel.WithRetryTimes(2_000, 3_000)

// Configure dead letter channel
topicConsumerChannel.WithDeadLetterChannelName("gomes.dlq")
```

##### MÃ©todos do Retry Handler

- **`NewRetryHandler(attemptsTime, handler)`**: Cria handler com tentativas configuradas
- **`Handle(ctx, msg)`**: Processa mensagem com retry automÃ¡tico
- **`WithRetryTimes(intervals...)`**: Configura intervalos de retry no consumer

#### Dead Letter Channel

O Dead Letter Channel Ã© um padrÃ£o que captura mensagens que falharam no processamento apÃ³s todas as tentativas de retry, permitindo anÃ¡lise posterior e recuperaÃ§Ã£o manual.

##### Como Funciona

Quando uma mensagem falha apÃ³s todas as tentativas de retry, ela Ã© enviada para um canal especial (Dead Letter Channel) com informaÃ§Ãµes sobre o erro e o payload original.

##### Diagrama de Fluxo do Dead Letter

```mermaid
flowchart TD
    A[Mensagem Processada] --> B{Sucesso?}
    B -->|Sim| C[Processamento ConcluÃ­do]
    B -->|NÃ£o| D[Retry Handler]
    D --> E{Todas Tentativas Falharam?}
    E -->|NÃ£o| F[Tentar Novamente]
    F --> D
    E -->|Sim| G[Dead Letter Handler]
    G --> H[Enriquecer Mensagem]
    H --> I[Enviar para DLQ]
    I --> J[Log do Erro]
    J --> K[Mensagem em DLQ]
```

##### Diagrama de ExecuÃ§Ã£o do Dead Letter

```mermaid
sequenceDiagram
    participant M as Message
    participant DLH as DeadLetterHandler
    participant OH as OriginalHandler
    participant DLC as DeadLetterChannel
    participant DLQ as DeadLetterQueue

    M->>DLH: Process Message
    DLH->>OH: Handle Message
    OH-->>DLH: Error

    DLH->>DLH: Convert Payload
    DLH->>DLH: Create DLQ Message
    DLH->>DLC: Send to DLQ
    DLC->>DLQ: Store Failed Message
    DLQ-->>DLC: Acknowledged
    DLC-->>DLH: Success
    DLH-->>M: Error Returned
```

##### Exemplo de ConfiguraÃ§Ã£o

```go
// 1. Configure canal de dead letter
publisherDlqChannel := kafka.NewPublisherChannelAdapterBuilder(
    "defaultConKafka",
    "gomes.dlq",
)

// 2. Registre o canal de dead letter
gomes.AddPublisherChannel(publisherDlqChannel)

// 3. Configure consumer com dead letter
topicConsumerChannel := kafka.NewConsumerChannelAdapterBuilder(
    "defaultConKafka",
    "gomes.topic",
    "test_consumer",
)
topicConsumerChannel.WithDeadLetterChannelName("gomes.dlq")
```

##### Estrutura da Mensagem Dead Letter

```go
type DeadLetterMessage struct {
    ReasonError string                 `json:"reason_error"`
    Payload     any                    `json:"payload"`
    Headers     map[string]string      `json:"headers"`
}
```

##### MÃ©todos do Dead Letter Handler

- **`NewDeadLetter(channel, handler)`**: Cria handler com dead letter
- **`Handle(ctx, msg)`**: Processa mensagem e envia para DLQ em caso de erro
- **`convertMessagePayload(msg)`**: Converte payload para formato DLQ
- **`makeDeadLetterMessage(ctx, msg, payload)`**: Cria mensagem DLQ enriquecida

### ğŸš€ Kafka

O driver Kafka implementa a integraÃ§Ã£o completa com Apache Kafka, fornecendo adaptadores para publicaÃ§Ã£o e consumo de mensagens com suporte a todas as funcionalidades do gomes.

#### ConfiguraÃ§Ã£o da ConexÃ£o

##### Exemplo de ConfiguraÃ§Ã£o BÃ¡sica

```go
// Crie uma conexÃ£o Kafka (singleton pattern)
connection := kafka.NewConnection("defaultConKafka", []string{"localhost:9093"})

// Registre a conexÃ£o no sistema
gomes.AddChannelConnection(connection)

// Conecte ao Kafka
err := connection.Connect()
if err != nil {
    log.Fatal("Failed to connect to Kafka:", err)
}
```

##### ConfiguraÃ§Ãµes AvanÃ§adas

```go
// ConfiguraÃ§Ã£o com mÃºltiplos brokers
connection := kafka.NewConnection(
    "production-kafka",
    []string{
        "kafka1.example.com:9092",
        "kafka2.example.com:9092",
        "kafka3.example.com:9092",
    },
)
```

#### Publisher Channel (PublicaÃ§Ã£o)

##### ConfiguraÃ§Ã£o do Publisher

```go
// Crie um publisher channel
publisherChannel := kafka.NewPublisherChannelAdapterBuilder(
    "defaultConKafka",        // Nome da conexÃ£o
    "gomes.topic",     // TÃ³pico de destino
)

// Registre o canal
gomes.AddPublisherChannel(publisherChannel)

// Use o canal atravÃ©s dos buses
commandBus := gomes.CommandBusByChannel("gomes.topic")
queryBus := gomes.QueryBusByChannel("gomes.topic")
eventBus := gomes.EventBusByChannel("gomes.topic")
```

##### TraduÃ§Ã£o de Mensagens

O sistema automaticamente traduz mensagens internas para o formato Kafka:

```go
// Mensagem interna
message := message.NewMessageBuilder().
    WithMessageType(message.Command).
    WithPayload(CreateUserCommand{Username: "john", Password: "123"}).
    WithHeaders(map[string]string{"correlationId": "123"}).
    Build()

// TraduÃ§Ã£o automÃ¡tica para Kafka
kafkaMessage := translator.FromMessage(message)
// Resultado: kafka.Message com headers e payload JSON
```

#### Consumer Channel (Consumo)

##### ConfiguraÃ§Ã£o do Consumer

```go
// Crie um consumer channel
consumerChannel := kafka.NewConsumerChannelAdapterBuilder(
    "defaultConKafka",        // Nome da conexÃ£o
    "gomes.topic",    // TÃ³pico de origem
    "test_consumer",         // Nome do consumer group
)

// Configure resiliÃªncia
consumerChannel.WithRetryTimes(2_000, 3_000)  // Retry com intervalos
consumerChannel.WithDeadLetterChannelName("gomes.dlq")  // DLQ

// Registre o canal
gomes.AddConsumerChannel(consumerChannel)
```

##### ConfiguraÃ§Ãµes do Consumer

```go
// ConfiguraÃ§Ãµes avanÃ§adas do consumer
consumerConfig := &kafka.ReaderConfig{
    Brokers:  []string{"localhost:9093"},
    Topic:    "gomes.topic",
    GroupID:  "test_consumer",
    MaxBytes: 10e6,  // 10MB por mensagem
}
```

#### Gerenciamento de ConexÃµes

##### Singleton Pattern

O driver Kafka usa singleton pattern para reutilizar conexÃµes:

```go
// Primeira chamada cria a conexÃ£o
conn1 := kafka.NewConnection("defaultConKafka", []string{"localhost:9093"})

// Segunda chamada retorna a mesma instÃ¢ncia
conn2 := kafka.NewConnection("defaultConKafka", []string{"localhost:9093"})

// conn1 == conn2 (mesma instÃ¢ncia)
```

##### MÃ©todos da ConexÃ£o

- **`Connect()`**: Estabelece conexÃµes com brokers Kafka
- **`Producer()`**: Retorna instÃ¢ncia do producer Kafka
- **`Consumer(topic, groupId)`**: Cria consumer para tÃ³pico especÃ­fico
- **`Disconnect()`**: Fecha conexÃµes e libera recursos
- **`ReferenceName()`**: Retorna nome de referÃªncia da conexÃ£o

#### TraduÃ§Ã£o de Mensagens

##### FromMessage (Interna â†’ Kafka)

```go
func (m *MessageTranslator) FromMessage(msg *message.Message) *kafka.Message {
    // Serializa headers
    headers := make([]kafka.Header, 0)
    for key, value := range msg.GetHeaders().ToMap() {
        headers = append(headers, kafka.Header{
            Key:   key,
            Value: []byte(value),
        })
    }

    // Serializa payload
    payload, _ := json.Marshal(msg.GetPayload())

    return &kafka.Message{
        Topic:   msg.GetHeaders().ChannelName,
        Key:     []byte(msg.GetHeaders().MessageId),
        Value:   payload,
        Headers: headers,
        Time:    time.Now(),
    }
}
```

##### ToMessage (Kafka â†’ Interna)

```go
func (m *MessageTranslator) ToMessage(kafkaMsg *kafka.Message) *message.Message {
    // Converte headers Kafka para headers internos
    headers := make(map[string]string)
    for _, header := range kafkaMsg.Headers {
        headers[header.Key] = string(header.Value)
    }

    // Cria mensagem interna
    return message.NewMessageBuilder().
        WithPayload(kafkaMsg.Value).
        WithHeaders(headers).
        WithChannelName(kafkaMsg.Topic).
        Build()
}
```

#### Exemplo Completo de Uso

```go
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // 1. Configure conexÃ£o Kafka
    gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    )

    // 2. Configure publisher
    publisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
    )
    gomes.AddPublisherChannel(publisherChannel)

    // 3. Configure DLQ publisher
    dlqPublisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.dlq",
    )
    gomes.AddPublisherChannel(dlqPublisherChannel)

    // 4. Configure consumer com resiliÃªncia
    consumerChannel := kafka.NewConsumerChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
        "test_consumer",
    )
    consumerChannel.WithRetryTimes(2_000, 3_000)
    consumerChannel.WithDeadLetterChannelName("gomes.dlq")

    gomes.AddConsumerChannel(consumerChannel)

    // 5. Registre handlers
    gomes.AddActionHandler(&CreateUserHandler{})

    // 6. Inicie o sistema
    gomes.Start()

    // 7. Configure event-driven consumer
    consumer, err := gomes.EventDrivenConsumer("test_consumer")
    if err != nil {
        panic(err)
    }

    // 8. Execute consumer
    go consumer.WithAmountOfProcessors(2).
        WithMessageProcessingTimeout(30000).
        WithStopOnError(false).
        Run(ctx)

    // 9. Publique mensagens
    commandBus := gomes.CommandBusByChannel("gomes.topic")
    commandBus.SendAsync(ctx, &CreateUserCommand{
        Username: "john_doe",
        Password: "secure_password",
    })

    // 10. Graceful shutdown
    <-ctx.Done()
    gomes.Shutdown()
}
```

### ConsideraÃ§Ãµes de Performance

- **Connection Pooling**: ReutilizaÃ§Ã£o de conexÃµes para melhor performance
- **Batch Processing**: Suporte a processamento em lote
- **Compression**: CompressÃ£o automÃ¡tica de mensagens grandes
- **Partitioning**: DistribuiÃ§Ã£o automÃ¡tica por partiÃ§Ãµes
- **Offset Management**: Gerenciamento automÃ¡tico de offsets

### Monitoramento e Debug

```go
// Visualize conexÃµes ativas
gomes.ShowActiveEndpoints()

// SaÃ­da exemplo:
// ---[Message System] Active Endpoints ---
// Endpoint Name                  | Type
// -------------------------------------------
// gomes.topic            | [outbound] Command-Bus
// gomes.topic            | [outbound] Query-Bus
// gomes.topic            | [outbound] Event-Bus
// gomes.topic            | [inbound] Event-Driven
// gomes.dlq              | [outbound] Dead-Letter
```

---

> ğŸ’¡ **Nota**: Esta documentaÃ§Ã£o Ã© um guia completo para desenvolvedores que desejam utilizar o gomes em suas aplicaÃ§Ãµes. O sistema foi projetado para ser intuitivo para desenvolvedores jÃºnior, mas poderoso o suficiente para cenÃ¡rios complexos de produÃ§Ã£o.
